\documentclass[main.tex]{subfiles}
\begin{document}
\section{Trying to understand renormalisation}
Originally, I was trying to understand how the amplitude is independent of the renormalisation scale $\mu_R$. One place in which it appears is obviously the renormalised, physical coupling constant $\alpha_R \equiv \alpha_s(\mu_R)$, but then it needs to cancel with $\mu_R$ from somewhere else. If we decide to introduce a UV cutoff $\Lambda$, it is easy to see how that happens.

We can impose that the physical coupling be equal to the matrix element at some kinematic point. We can experimentally measure that value in a collider. On the other hand, we can calculate it using the bare parameters in normal perturbation theory. See Lancaster Example 34.1 (p. 303) and Schwartz p. 298. One can then express the bare couplings in terms of the physical ones and make that replacement in any future calculation. This has the effect of essentially subtracting a matrix element calculated at a particular kinematic point, e.g.
\begin{equation}
    A = \lambda_R(\mu_R) + \lambda_R^2(\mu_R) \ln \left( \frac{\mu_R^2}{s} \right) + \ldots
\end{equation}
This subtraction technique is known as physical, or on-shell, renormalisation.

However, if we don't want to use a cutoff, we need to resort to dimensional regularisation to keep track of the UV divergences as poles in $\varepsilon$. How then do we make sense of the cancellation of $\mu_R$ between the coupling constants and other terms? In fact, in dim-reg, ultraviolet divergences show up as poles of
the form $1/\varepsilon$. In fact, the coefficients of large logarithms of the the physical scale $s_0$ \footnote{$s_0$ represents collectively the values of the Mandelstam variables $s_{ij}$ at which we define the physical coupling} are connected to UV divergences, as they would be in a theory with a UV regulator $\Lambda$ (in the references above, we will see functions like $\ln \frac{\Lambda}{s_0}$. See Schwartz Sec 23.1. Thus, the explicit dependence of the logs on $\mu_R$ now hides as poles in $1/\varepsilon$ (or strictly speaking, $1/\varepsilon_{UV}$.

Rather than using the `subtraction' renormalisation described above, which relies on computing physical quantities with a cutoff $\Lambda$ and then cancelling it out, it is more common to use `renormalised perturbation theory', where the renormalised couplings are used right from the beginning:
\begin{equation}
    x_B \rightarrow Z_x x_R
\end{equation}
The multiplicative factor $Z_x$ absorbs the divergences from $x_B$, making $x_R$ finite. This means that it is in itself divergent - indeed, adding this factor is equivalent to adding counterterms to the Lagrangian that are designed precisely to cancel the infinite parts of amplitudes.

Each factor $Z_x$ can be expanded:
\begin{align}
    Z_x &= 1 + \delta_x \\
        &= 1 + \left( \frac{\alpha}{4 \pi} \right) c_{x,\,1} + \left(\frac{\alpha}{4 \pi}\right)^2 c_{x,\,2} \ldots
\end{align}
(careful with the factors of $2, \pi$). The $\delta_x$ can be calculated from Feynman diagrams by imposing the divergent parts cancel out (and by imposing the `renormalisation conditions'?). The 1-loop calculations are done explicitly in e.g. the QCD notes by Alex Huss from the IPPP PhD course or see Schwartz Sec. 26.4.

The $\beta$-function can be calculated by imposing that the physical Lagrangian should not depend on $\mu_R$ (see Schwartz Sec 26.6). It then follows from this calculation that the $\beta_0$ coefficients is equal to $\delta_g$ counterterm at 1-loop, i.e. $c_{g,\,1}$ (up to some factors of $2, \varepsilon$). See Schwartz Eq. 26.94, but \textcolor{red}{be careful!}. The renormalised Lagrangian in Eq. 26.54 defines $Z_{A^3} = Z_g (Z_3)^\frac{3}{2}$, so the $\delta_{A^3}$ given in Sec. 26.5.3 is NOT the usual $\delta_g$. In fact, to relate them, we simply need to $\delta_g = \delta_{A^3} -\frac{3}{2}\delta_3$. Then, we recover the usual term:
\begin{equation}
    c_{g,\,1} = \frac{\beta_0}{\varepsilon}
\end{equation}
Thus, we see that the dependence of $\alpha_s$ on $\mu_R$ can cancel out with the dependence hidden as UV divergences in the form of $1/\varepsilon$ in the $c_{g,\,1}$.

\section{Note on the IBP reduction}
Let us now discuss in detail the approach we take in the IPB reduction of integrals present in the maximal topologies $T$ onto a MI basis. Overall, IPB relations allow us to express each helicity amplitude coefficient of \cref{eq:ampcoeffinv} in terms of a much smaller number of MIs:
\begin{equation} \label{eq:ampafterIBP}
	a_i^{(L)} = \sum_{i=1}^{|\vv{\text{MI}}|} c_i(p(\vec{x}), \eps) \times \text{MI}_i(p,\eps)\,,
\end{equation}
where $|\vv{\text{MI}}|$ denotes the total number of linearly independent MIs in all the families. Once again, the reduction coefficients $c_i$ introduced by the IPB relations are rational functions of external momenta $p$ (expressed through the MTVs: $\vec{x} = \{x_1, x_2, x_3\}$), as well as the dimensional regulator $\eps$. There is a certain subtlety related to the number of MIs after the reduction of multiple families:
\begin{equation} \label{eq:noofmis}
	|\vv{\text{MI}}| \equiv |\vv{\text{MI}}_{\sum_T T}| \neq \sum_{\mathclap{\substack{T \in \\ \text{maximal} \\ \text{topologies}}}} |\vv{\text{MI}}_T| \,.
\end{equation}
%By their very nature, the IBP relations can only provide the reduction of integrals within one family. Therefore, for $N_T$ integral families, we need to build and solve $N_T$ IBP systems. 
That is, the number of MIs for all families considered together is not the same as the sum of numbers of MIs for these families considered separately. This statement might seem surprising. Indeed, if we formulate one big system of pure IPB relations between integrals in all the families and perform the reduction, the resultant MI basis is equal to the sum of the bases obtained by solving smaller systems of IBP relations within each family one by one. This is because integrals in different families live in different vector spaces and there cannot be inter-family IPB relations. However, integrals belonging to sectors other than the top sector can often be mapped between families. \JK{Maybe it would be nice to include a simple example in a Fig.}. Therefore, an amplitude reduced using $N_T$ separate IPB systems contains leftover MIs that can be further reduced onto each other with the help of non-IPB mappings. To avoid this redundancy, we typically build a combined system which covers all the families in the problem. It contains the pure IPB relations, as well as the additional inter-family mappings\footnote{In practice, these mappings are found by comparing integrals based on their representation in terms of the $\mathcal{U}$ and $\mathcal{F}$ Symanzik polynomials (see Section~4 of \cite{Lee:2012cn} and \cite{Pak:2011xt}).}. Unfortunately, for large $N_T$, this often leads to a prohibitively long time required to solve the system and may even constitute the main bottleneck of the whole amplitude computation. 

There is, however, a more efficient way of performing the IPB reduction. Recall that the integral families fed into the reduction are defined by their propagators and ISPs. It is not hard to see that each family can therefore be identified by its `type' and a permutation of external legs within that type. Let us refer to the topologies of \cref{fig:pentatriangle} as penta-triangle$(ijkl)$, that of \cref{fig:double-box} as double-box$(ijkl)$ and those of \cref{fig:crosseddouble-box} as crossed-double-box$(ijkl)$. Moreover, in the presence of external masses, we need to further distinguish between topology subtypes based on the position of the mass which breaks the symmetry of integrals under the permutations of external legs. Indeed, the three penta-triangles belong to distinct `mzz', `zmz' and `zzz' subtypes (we follow the naming convention of \cite{Abreu:2020jxa}), while the crossed-double-boxes have only two subtypes, which we call `mz' and `zz'. Topologies with masses in the remaining positions can always be mapped onto these subtypes, which is evident from the graphical representation in \cref{fig:int-fams}. Indeed, note that the single-external-mass double-box effectively has just one configuration, as the remaining three are trivially mapped onto it by re-orientating their Feynman diagrams.

It is not hard to notice that if two given topologies are of the same (sub)type and differ only by a permutation $\sigma$ of the massless legs, i.e.~$T'=T(\sigma(ijkl))$, then the IPB reduction of any integral within the permuted family $T'$ can be expressed as a permutation of the reduction of the corresponding integral in the original family $T$ \JK{Does this fact need any further justification?}
\begin{subequations}
\begin{align}
	I_{T(ijkl)} &= \sum_{i=1}^{|\vv{\text{MI}}_T|} c_i(\vec{x}, \eps) \times \text{MI}_{T(ijkl),\,i} \,, \\
	\implies I_{T(\sigma(ijkl))} &= \sum_{i=1}^{|\vv{\text{MI}}_T|} c_i(\sigma(\vec{x}), \eps) \times \text{MI}_{T(\sigma(ijkl)),\,i}\,. \label{eq:permutedreduction}
\end{align}
\end{subequations}
\JK{I think the notation here is crap, but I can't think of anything better for now.} That is, the new reduction coefficients $c_i$ are obtained as a permutation of the MTVs in the old ones, while the new MIs are obtained by permuting the massless legs in all the propagators and ISPs\footnote{In the case of UT MIs, which are often defined as combinations of integrals $I_T$, we also need to permute any potential kinematic prefactor of these integrals according to $\sigma$.}
\begin{equation}
	\text{MI}_{T',\,i}(p, \eps) = \text{MI}_{T,\,i} (\sigma(p), \eps)\,.
\end{equation}
We now see that we do not need to explicitly perform the IBP reduction for up to $3!$ permutations of the six topology subtypes in \cref{fig:int-fams}. We only need to do it once per maximal topology --- in an arbitrarily chosen permutation of each topology, that is $T_{\sigma_\text{id}}$. Then, the reduction of any permutation of this family is obtained by considering $\sigma$ such that $\sigma(\sigma_{\text{id}})$ brings us onto the target topology $T' = T_{\sigma(\sigma_\text{id})}$ and applying \cref{eq:permutedreduction}. Since the coefficients are rational functions of $\vec{x}$ and $\eps$, permuting them is trivial. Moreover, the rationality means that this new approach to IPB reduction is perfectly compatible with the finite field sampling procedure. Permuting the coefficients amounts to a change of variables, which can be implemented over the field. Thus, we never have to know and permute the analytic form of the IPB coefficients, which leads to a significant reduction in the computational cost.

Let us now discuss a small issue with this new strategy. As pointed out below \cref{eq:noofmis}, subtopologies of distinct families often have coinciding MIs. Thus, the total number of MIs is smaller than the sum of MIs in the individual families. This redundancy is automatically taken care of in the traditional approach to the IPB reduction, but not the one we have described above, since the reduction is performed only within the `main' families $T_{\sigma_\text{id}}$. Thus, the amplitude obtained in this approach will contain MIs which are in fact not fully linearly independent. Strictly speaking, there is no requirement for the amplitude to be expressed in terms of independent objects. However, it is usually desirable to do so, as this ensures that any cancellations happen analytically and prevents instabilities or issues with precision during the numerical evaluation of the amplitude. Moreover, it is more computationally efficient, as it reduces the number of coefficients that have to be processed when expanding the amplitude onto special functions.

In practice, we obtain these missing relations between MIs by performing their reduction in the traditional approach (i.e.~all families included together in one system) in \texttt{LiteRed}. This expresses the MIs from all families in terms of the truly independent ones 	
\begin{equation}
	\text{MI}_{i} = \sum_j^{|\vv{\text{MI}}|} f_{ij}(p, \eps) \times \text{MI}_j \qquad i \in \left\{1, \ldots, \sum_T |\vv{\text{MI}}_T|\right\}\,,
\end{equation}
where $|\vv{\text{MI}}| = |\vv{\text{MI}}_{\sum_T T}|$, as defined earlier. This additional MI reduction does not present such a high complexity as the reduction needed for the amplitude itself. Firstly, the identities generated through the Laporta algorithm only need to cover the rank and number of `dotted' (raised to a power $\ge2$) propagators present in the MI bases, rather than the full amplitude. Secondly, all the missing relations between MIs can be worked out once and for all --- they will be applicable to any process at the same loop order and number of particles (and external masses), since the IPB reduction is specific only to the kinematic setup. Finally, an extremely useful property of UT integrals is that any inter-family relations between them cannot contain any dependence on the kinematic variables, i.e.~$f(p, \eps) \rightarrow f(\eps)$ \JK{Simone: why is that true? Something about the Feynman parametrisation with the U/F polynomials?}. Thus, when using UT bases, which has become the standard in modern amplitude computations, this additional reduction can be performed with the kinematic variables set to random numerical values (subject to momentum conservation).

Having obtained the missing relations between MIs, we apply them to our amplitude and collect the coefficients of the true, linearly independent MIs. Overall, we find that this alternative approach performs much better than the previously employed strategy of considering all integral families together in one shared IPB system. The benefit grows with the number of permutations of the maximal topologies, since including additional families in the IPB system is expensive, but numerically permuting the solution from one family onto another is cheap.
\end{document}