\documentclass[main.tex]{subfiles}
\begin{document}
\chapter{Tools for calculating scattering amplitudes}
In this chapter, we focus on various aspects of the computation of two-loop QCD scattering amplitudes for high-multiplicity processes. It is important to note that there is currently no one-size-fits-all approach that would allow us to compute all the desired amplitudes at a press of a button. In practice, we use a collection of methods that are most appropriate for the task at hand. For processes at the limit of current capabilities, these tools need to be further improved or replaced with novel ideas. To this end, much work has been done by the theory community in recent years. Unfortunately, due to the overwhelming algebraic and analytic complexity, many calculations still present challenges beyond the reach of current technology. 
\begin{figure}[t]
\begin{tikzpicture}
	\node (feynman) [greenrec] {Feynman diagrams};
	\node (colour)  [redrec,right of=feynman,xshift=4cm] {Colour decomposition};
	\node (topos)   [redrec,right of=colour,xshift=4cm] {Helicity amplitudes};
	\node (reduction) [bluerec,below of=topos,yshift=-2cm] {\parbox{0.3\textwidth}{\centering Integrand reduction onto \\ maximal topologies}};
	\node (IBPs)    [bluerec,left of=reduction,xshift=-4cm] {IBP reduction};
	\node (spfns)   [bluerec,left of=IBPs, xshift=-4cm] {\parbox{0.3\textwidth}{\centering Expansion of MIs onto \\ special function basis}};
	\node (sub)     [bluerec,below of=spfns,yshift=-2cm] {Pole subtraction};
	\node (finrem)  [bluerec,right of=sub,xshift=4cm] {Finite remainder};
	\node (rec)  [bluerec,right of=finrem,xshift=4cm] {Reconstruction};
	\node (qgraf) [below of=feynman, opacity=0.7] {\textcolor{green}{\Large QGRAF}};
	\node (mma) [below right of=colour, xshift=1.5cm, yshift=-0.3cm, opacity=0.7] {\textcolor{red}{\Large Mathematica/FORM}};
	\node (ff) [below of=IBPs, yshift=-0.5cm,opacity=0.7] {\textcolor{blue}{\Large finite fields}};
		
	\draw[->] (feynman.east) -- (colour.west);
	\draw[->] (colour.east) -- (topos.west);
	\draw[->] (topos.south) -- (reduction.north) node[midway,right] {$d=4-2\epsilon$};
	\draw[->] (reduction.west) -- (IBPs.east);
	\draw[->] (IBPs.west) -- (spfns.east);
	\draw[->] (spfns.south) -- (sub.north);
	\draw[->] (sub.east) -- (finrem.west) node[midway,above] {$\epsilon \rightarrow 0$};
	\draw[->] (finrem.east) -- (rec.west);
\end{tikzpicture}
\caption{A schematic overview of the workflow we adopt to compute scattering amplitudes.}
\label{fig:outline}
\end{figure}
The goal of this chapter is to provide an overview of the method we adopt in amplitude computations, as well as the problems that invariably follow. The procedure involves several highly non-trivial steps. To help the reader retain the `big picture' of the workflow, we present its schematic outline in Fig.~\ref{fig:outline}.  Each step is discussed in more detail below. 

\section{Feynman diagrams}
The starting point of our amplitude computation for a given process is the generation of all Feynman diagrams contributing to this process at the desired loop order. Feynman diagrams provide a pictorial representation of the ways in which the interaction can occur.
%time-ordered correlation functions that contribute to the $S$-matrix element
At the same time, the corresponding mathematical expressions can be easily recovered using Feynman rules, which can be derived form the Lagrangian of the theory under consideration \JK{(Feynman rules relevant to our work are listed in Appendix~\ref{app:feynmanrules})}. As such, these diagrams are an indispensable tool of any perturbative calculation. In practice, it can be observed that usually their number grows faster than exponentially as we increase the loop order or multiplicity (see Table~\ref{tab:ndiags} for an example). To handle the combinatorial complexity, we generate the relevant Feynman diagrams using $\texttt{QGRAF}$~\cite{Nogueira:1991ex}. This programme has the advantage of granting the user a large degree of control over the diagrams. For example, one can constrain it to generate diagrams without self-energy insertions or with a specified total power of the coupling constant. \JK{should I even mention that?}
\begin{table}[b]
	\begin{center}
		\begin{tabular}{r|c|c|c|c|c|c|c|c}
			  $n$ & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
			\hline
			$n$ gluons   & -- & -- & 1 & 4 & 25 & 220 & 2485 & 34300 \\
			$q\bar{q} + n$ gluons & 1 & 3 & 16 & 123 & 1240 & 15495 & 231280 & 4016775 \\
		\end{tabular}
	\end{center}
 \caption{Number of tree-level diagrams contributing to selected processes with $n$ gluons.}
 \label{tab:ndiags}
\end{table}

\section{Colour decomposition}
Having generated the Feynman diagrams, we substitute the Feynman rules for the propagators and vertices using \texttt{Mathematica}. At this point, our QCD amplitude contains both colour and kinematic information. The idea of colour ordering is to reorganise the amplitude such that these two components separate: a purely kinematic amplitude is multiplied by the corresponding colour factor. In other words, we perform the decomposition of the full amplitude in colour space, according to a chosen colour basis. Roughly speaking:
\begin{equation}
    \ampl{n}{} = \sum_i \text{(colour)}_i \times A_{n\,i} \,, 
\end{equation}
where $A_{n\,i}$ are the colour-ordered amplitudes (also known as colour-stripped or partial amplitudes). The motivation behind this decomposition is that the colour-ordered amplitudes turn out to be significantly simpler to calculate.

The choice of the colour basis is not unique. We adopt the decomposition according to traces of the $SU(N_c)$ generators in the fundamental representation. As an example, let's look at the 4-gluon scattering at tree-level:
\begin{equation} \label{eq:3grule}
\feynmandiagram [baseline = (i.base), horizontal = i to j] {
    a1 [particle={$A^{a_1}_{\mu_1}$}] -- [gluon, momentum=$p_1$] i;
    a2 [particle={$A^{a_2}_{\mu_2}$}] -- [gluon, momentum=$p_2$] i;
    i -- [gluon] j;
    a3 [particle={$A^{a_3}_{\mu_3}$}] -- [gluon, momentum=$p_3$] j;
    a4 [particle={$A^{a_4}_{\mu_4}$}] -- [gluon, momentum=$p_4$] j;
    };
    \xrightarrow{colour}
    f^{a_1a_2b}f^{ba_3a_4} \,.
\end{equation}
The colour factor of this diagram can be expressed in terms of the generators using Eqs.~\ref{eq:liealgebra} and ~\ref{eq:fierz}:
\begin{equation}
    f^{a_1a_2b}f^{ba_3a_4} = -\frac{1}{T_F}\left(\tr[T^{a_1} T^{a_2} T^{a_3} T^{a_4}] - \tr[T^{a_1} T^{a_2} T^{a_4} T^{a_3}] - \tr[T^{a_1} T^{a_3} T^{a_4} T^{a_2}] + \tr[T^{a_1} T^{a_4} T^{a_3} T^{a_3}] \right)\,.
\end{equation}
The colour factors of the $t$- and $u$-channels can be expressed in a similar way. Combining the contributions from the three channels and using the cyclicity of the trace, we can organise the 4-gluon amplitude at tree-level as follows:
\begin{equation}
    \ampl{4}{(0)} =  g^2 \left( \tr[T^{a_1} T^{a_2} T^{a_3} T^{a_4}]\,A_{4}^{(0)}[1234] + \text{permutations of } (234) \right) \,.
\end{equation}
In the general case, this formula reads:
\begin{equation} \label{eq:colour-decomposition}
    \ampl{n}{(0)} = g^{n-2} \sum_{\sigma \in S_{n-1}} \tr\left[T^{a_1} T^{\sigma(a_2} \ldots T^{a_n)}\right] A_n^{(0)} \left[1\,\sigma(2\ldots n)\right] \, ,
\end{equation}
where the sum is over the set of all \textit{non-cyclic} permutations of $n-1$ particles. Similar colour decompositions can be derived for amplitudes involving quarks, as well as beyond tree-level~\cite{Dixon:1996wi}. At loop-level, the colour basis contains products of traces, in addition to single trace structures. 

The colour-ordered amplitudes are calculated by adding up the kinematic parts of all Feynman diagrams contributing to a given colour factor. They are gauge invariant and satisfy a number of important identities:
\begin{align}
    A_n[123\ldots n] &= A_n[23\ldots n\,1]\,, && \text{cyclicity} \\
    A_n[123\ldots n] &= (-1)^n A_n[n \ldots 231] \,, && \text{reflection} \\
    A_n[123 \ldots n] &+ A_n[213 \ldots n] +  A_n[231 \ldots n] +  \ldots + && A_n[23 \ldots 1\,n]  = 0 \,, \nonumber \\ 
    & && U(1) \text{ decoupling} \\
    A_n[1, {\alpha}, n, {\beta}] &= (-1)^{|\beta|} \sum_{\mathclap{\sigma \in OP(\{\alpha\} \cup \{\beta^T\})}} A_n[1, \sigma, n] \,, && \text{Kleiss-Kuiff relations}
\end{align}
\JK{fix alignment!!!} where the sum is over permutations in the joint set $\{\alpha\} \cup \{\beta^T\}$ such that the order within the individual sets is preserved, and $\{\beta^T\}$ is the reversal of the set $\{\beta\}$~\cite{Mangano:1990by, Kleiss:1989616, Bern:2008qj}. Crucially, these properties allow us to reduce the number of independent amplitudes that need to be computed. In fact, for $n$-gluon scattering, this number is just $(n-2)!$\,.

\section{Helicity amplitudes}
After colour decomposition, our $L$-loop scattering amplitude contains purely kinematic information. The kinematic part of the Feynman rules for external states carries information about the spins and polarisations of particles: for massless spin\=/1/2 fermions, we use $\pm$ helicity states to differentiate between the two solutions to the Dirac equation, while for massless spin\=/1 bosons, they denote the two polarisation vectors. From the experimental perspective, we are rarely interested in differentiating between the spin states of individual particles. Usually, a beam of particles with random spins undergoes scattering and we look at the total number of particles outgoing in a certain direction. Thus, to calculate the corresponding cross-section, we should average over the initial spin states and sum over the final ones. This can be achieved in two different ways: 
\begin{enumerate}
    \item perform the amplitude calculation without specifying the helicity states, i.e. square the amplitude, then do the spin sums that appear at the level of $|\ampl{}{}|^2$ using completeness relations Eqs.~\ref{eq:completeness:fermionsm, eq:completeness:bosons}
    \item specify the helicity states of external particles, compute each \textbf{helicity amplitude} separately, square them and sum over all relevant helicity configurations
\end{enumerate}
In our computations, we will adopt the latter method. We denote an $L$-loop helicity amplitude as:
\begin{equation} \label{eq:helampdef}
    \ampl{n}{(L),\,\{h\}} \equiv \ampl{n}{(L)}(1^{h_1}2^{h_2} \ldots n^{h_n})\,,
\end{equation}
where the superscript $\{h\}$ is understood as the set of helicities of the $n$ particles, but will be usually omitted since we will exclusively compute helicity amplitudes. The full, spin-summed amplitude can then be recovered through:
\begin{equation}
    \ampl{n}{(L)} = \sum_{\mathclap{\substack{\text{helicity} \\ \text{configurations}}}} \ampl{n}{(L),\,\{h\}} \,.
\end{equation}
At the cross-section level:
\begin{equation}
    \left|\ampl{n}{(L)}\right|^2 = \sum_{\mathclap{\substack{\text{helicity} \\ \text{configurations}}}} \left|\ampl{n}{(L),\,\{h\}} \right|^2 \,.
\end{equation}
It is important to note that the sum only includes the squares of individual helicity amplitudes --- there are no interferences between different helicity configurations.

There are several strong advantages to this approach. Firstly, it is easy to see that the number of terms that need to be processed is significantly smaller than in method~(1) \JK{check with SB if the argument below even makes sense...}. Consider the expansion of an amplitude in the coupling constant $\alpha$ up to NNLO:
\begin{equation}
    \ampl{}{} = \ampl{}{(0)} + \alpha \ampl{}{(1)} + \alpha^2 \ampl{}{(2)} + \order{\alpha^3} \,.
\end{equation}
Then, at the level of the cross-section, we have the following contributions:
\begin{equation}
    |\ampl{}{}|^2 = |\ampl{}{(0)}|^2 \,+\,\alpha\,2\,\mathrm{Re}\left(\ampl{}{(0)\ast}\ampl{}{(1)}\right) \,+\, \alpha^2 \left(2\,\mathrm{Re} \left(\ampl{}{(0)\ast}\ampl{}{(2)}\right) + |\ampl{}{(1)}|^2 \right) \,+\, \order{\alpha^3}\,.
\end{equation}
Let us also schematically write each $L$-loop amplitude as a sum of $m_L$ Feynman diagrams: $\ampl{}{(L)} = d^{(L)}_1 + d^{(L)}_2 + \ldots + d^{(L)}_{m_L}$. Then, at LO:
\begin{equation}
    \left|\ampl{n}{(0)}\right|^2 = \sum_{\mathclap{\substack{\text{hel.} \\ \text{confs.}}}} \left|\ampl{n}{(0),\,\{h\}} \right|^2 = \sum_{\mathclap{\substack{\text{hel.} \\ \text{confs.}}}} \left|d^{(0)\,,\{h\}}_1 + d^{(0)\,,\{h\}}_2 + \ldots + d^{(0)\,,\{h\}}_{m_0} \right|^2 \,.
\end{equation}
Each term in this sum has all helicities fixed and there are no spin sums to be performed (when evaluated at a chosen phase-space point, it is just a complex number). Thus, the number of terms we need to process at LO is $m_0 n_h$, where $n_h$ is the number of independent helicity configurations. On the other hand, according to method (1), we have:
\begin{equation}
    \left|\ampl{n}{(0)}\right|^2 = \left(d^{(0)}_1 + d^{(0)}_2 + \ldots + d^{(0)}_{m_0} \right) \left(d^{(0)\ast}_1 + d^{(0)\ast}_2 + \ldots + d^{(0)\ast}_{m_0} \right)\,,
\end{equation}
which means we need to interfere the diagrams with each other and perform the spin sums. Thus, there are $m_0^2$ terms to be processed. The scaling for higher loop orders is listed in Table~\ref{tab:nterms}. For small $L$, the advantage of using helicity amplitudes might be minimal (or in fact, it might be detrimental to do so). For $L\geq2$, however, the advantage becomes apparent, especially that due to the symmetries of colour-ordered amplitudes, $n_h$ is usually much smaller than $2^n$. Moreover, it turns out that not all helicity amplitudes are equally challenging to compute, as we will see in the next section. In fact, a host of them vanishes altogether (at least at tree-level). Finally, guided by experience, it is possible to choose the reference vectors of external polarisations such that the computation of non-zero amplitudes becomes easier. 

When dealing with helicity amplitudes, it is conventional to introduce nomenclature encoding the number of positive/negative helicity particles involved in the process. Consider $2\rightarrow n$ gluon scattering where the outgoing momenta all have opposite helicities to the incoming ones: $1^-2^- \rightarrow 3^+ \ldots n^+$. We call such a configuration `helicity violating'. We can cross particles 1 and 2 to the final state, which changes their helicities: $0\rightarrow 1^+2^+ \ldots n^+$. This corresponds to the `all-plus' amplitude $A_n(1^+2^+ \ldots n^+)$ with all momenta outgoing. In the next section, we will show that for gluon scattering at tree-level, this amplitude vanishes for all $n$. If we flip one helicity in the final state: $1^-2^- \rightarrow 3^- \ldots n^+$, this corresponds to $A_n(1^+2^+3^-4^+ \ldots n^+)$, which also turns out to vanish at tree-level. The first non-zero configuration is $1^-2^- \rightarrow 3^-4^- \ldots n^+$, which corresponds to: $A_n(1^+2^+3^-4^-5^+ \ldots n^+)$. For this reason, amplitudes with exactly two negative helicity particles are called \textbf{maximally helicity violating (MHV)}. Similarly, amplitudes with exactly two positive helicities are known as anti-MHV. Furthermore, configurations with $2+k$ negative/positive helicities are referred to as $\text{N}^k\text{MHV}/\text{anti-N}^k\text{MHV}$. Tree-level MHV amplitudes are remarkably simple, as we will demonstrate in the next section. 
\begin{table}[t]
	\begin{center}
		\begin{tabular}{c|c|c|c}
			  \# terms & LO & NLO & NNLO \\
			\hline
			Method (1) & $m_0^2$ & $m_0^2 + m_0 m_1$ & $m_0^2 + m_0 m_1 + m_1^2 + m_0 m_2$ \\
			Method (2) & $m_0 n_h$ & $(m_0+m_1)n_h$ & $(m_0+m_1+m_2)n_h$ \\
		\end{tabular}
	\end{center}
 \caption{Number of terms to be processed in the computation of the squared amplitude $\left|\ampl{}{}\right|^2$ \textit{up to and including} a given order in the coupling constant, assuming there are $m_L$ diagrams at $L$ loops. The meaning of methods (1) and (2) is outlined in the text around Eq.~\ref{eq:helampdef}.}
 \label{tab:nterms}
\end{table}
\section{Spinor helicity formalism} \label{sec:spinhelform}
In Section~\ref{sec:QEDintro}, we saw that for massless particles, the Dirac spinor splits into two Weyl spinors that do not mix and are associated with the helicity of the particle. Therefore, we might be tempted to think that helicity amplitudes are better described using a notation specific to the two-component Weyl spinors, which are acted on by the familiar Pauli matrices. Indeed, the powerful \textbf{spinor-helicity formalism} provides a neat way to express helicity amplitudes based on these considerations\footnote{In case the notation that follows appears daunting, we refer the reader to Ref.~\cite{ElvangHuang} for an in-depth discussion of the topic and useful exercises.}.

As a first step, let's see how we can move from working with the four-component objects to two-component ones. We can write a `slashed' momentum $\slashed{p}$ as:
\begin{equation} \label{eq:pslashed1}
    \slashed{p} = p_\mu \gamma^\mu = p_\mu
    \begin{pmatrix}
    0 & (\sigma^\mu)_{a\dot{b}} \\
    (\bar{\sigma}^\mu)^{\dot{a}b} & 0
    \end{pmatrix}
    \equiv
    \begin{pmatrix}
    0 & p_{a\dot{b}} \\
    p^{\dot{a}b} & 0 
    \end{pmatrix} \, ,
\end{equation}
with both dotted and un-dotted indices running over $\{1,2\}$ and $(\sigma^\mu)_{a\dot{b}} \equiv (1, \, \sigma^i), \, (\bar{\sigma}^\mu)^{\dot{a}b} \equiv (1, \, -\sigma^i)$, where $\sigma^i$ are the three Pauli matrices. The momentum bispinors $p^{\dot{a}b}$ and $p_{a\dot{b}}$ can be thought of as $(2 \times 2)$ matrices and it is straightforward to show that:
\begin{equation}
    \det p_{a\dot{b}} = \det p^{\dot{a}b} = m^2\,.
\end{equation}
For massless particles, this determinant vanishes and the matrix can be expressed as an outer product of two vectors\footnote{The determinant of a matrix is 0 only if its column/row vectors are linearly dependent, which implies that its rank is 1. A rank-1, $(n \times n)$ matrix can always be expressed as the outer product of two nonzero vectors of length $n$.}. The vectors we will choose are the momentum space Weyl spinors $\lambda_a$  and $\tilde{\lambda}_{\dot{a}}$ (sometimes referred to as helicity spinors). They are the two-component, left- and right-handed equivalents of the $u(p)$ and $v(p)$ Dirac spinors, with the corresponding helicities $-$ and $+$, respectively. We thus write:
\begin{align} \label{eq:outerproduct}
    p_{a\dot{b}} = \lambda_a \tilde{\lambda}_{\dot{b}} && p^{\dot{a}b} = \tilde{\lambda}^{\dot{a}} \lambda^b\,,
\end{align}
and the raising and lowering of indices is achieved through:
\begin{align}
    \lambda^a = \varepsilon^{ab} \lambda_b && \tilde{\lambda}^{\dot{a}} = \varepsilon^{\dot{a}\dot{b}} \lambda_{\dot{b}} \,,
\end{align}
with the two-dimensional Levi-Civita tensor defined as:
\begin{equation}
    \varepsilon^{ab} = \varepsilon^{\dot{a}\dot{b}} = -\varepsilon_{ab} = -\varepsilon_{\dot{a}\dot{b}} = 
    \begin{pmatrix}
        0 & 1 \\
        -1 & 0
    \end{pmatrix}\,.
\end{equation}
In practice, it can be rather cumbersome to keep track of the dotted and un-dotted indices, as well as their lower or upper positions at the spinors. It is more intuitive to trade this notation for spinor brackets\footnote{The choice of assignment of dotted/un-dotted indices and angle/square brackets to either $\lambda$ or $\tilde{\lambda}$ is arbitrary. Different conventions are seen throughout literature - the only requirement is internal consistency.}:
\begin{align} \label{eq:lambdatobraket}
    \lambda_a  &\rightarrow \ketsq{p}_a,  &&\tilde{\lambda}_{\dot{a}} \rightarrow \bra{p}_{\dot{a}}\,, \nonumber \\
    \lambda^a  &\rightarrow \brasq{p}^a  &&\tilde{\lambda}^{\dot{a}} \rightarrow \ket{p}^{\dot{a}} \,.
\end{align}
We can then write Eq.~\ref{eq:pslashed1} as:
\begin{align} \label{eq:pslashed2}
    \slashed{p} = \ket{p}\brasq{p} && \slashed{p} = \ketsq{p} \bra{p} \,,
\end{align}
while the massless Dirac equation becomes the massless Weyl equation:
\begin{align} \label{eq:weyleq}
    \slashed{p}\ket{p} = 0 && \slashed{p}\ket{p} = 0\,.
\end{align}
In the above, $\slashed{p}$ is a small abuse of the `slashed' notation --- what it really means is a contraction of $p_\mu$ with $\sigma^\mu$ or $\bar{\sigma}^\mu$, rather than $\gamma^\mu$. The appropriate Lorentz vector can be chosen by looking at the indices of the square/angle spinors that $p^\mu$ is sandwiched between. However, the power of spinor-helicity formalism lies in the fact that in practice, we do not ever need to perform such explicit summation over indices and instead work with identities at the level of angle and square brackets:
\begin{align}
    \braket{ij} \equiv \bra{i}_{\dot{a}} \ket{j}^{\dot{a}}&& \braketsq{ij} \equiv \brasq{i}^a \ketsq{j}_a \,.     
\end{align}
It is straightforward to show that because the indices are raised and lowered using the Levi-Civita symbol, these brackets must be \textit{antisymmetric}:
\begin{align}
    \braket{ij} = -\braket{ji} && \braketsq{ij} = -\braketsq{ji}\,.
\end{align}
We can also formulate angle-square or square-angle brackets as follows:
\begin{align}
    \langle ikj ] \equiv \bra{i} \slashed{k} \ketsq{j} && [ikj\rangle \equiv \brasq{i} \slashed{k} \ket{j}\,.
\end{align}
To choose the right $\slashed{k}$ from Eq.~\ref{eq:pslashed2}, we just need to remember that $\langle ik] = [ik\rangle = 0$. These brackets can be extended to arbitrary lengths by inserting additional slashed momenta inside. 

We note some very useful identities\footnote{Naturally, the Schouten, Gordon and Fierz identities also hold if we exchange all angle and square brackets. Wherever $\gamma^\mu$ appears, it is understood as either $\sigma^\mu$ or $\bar{\sigma}^\mu$, as explained earlier.}:
\begin{subequations} \label{eq:spinorsids}
    \begin{align}
        \braket{ii} = \braketsq{ii} = 0 && \text{by antisymmetry} \label{eq:iieq0} \\
        s_{ij} = -\braket{ij}\braketsq{ij} && \text{(for massless momenta)} \\
        \braketsq{ij}^{\ast} = \braket{ji} && \text{(for real momenta)} \label{eq:complexconjbracket} \\
        \sum_{i=1}^n \ketsq{i}\bra{i} = \sum_{i=1}^n \ket{i}\brasq{i} = 0 && \text{momentum conservation} \label{eq:spinmomcons}\\
        \ket{i}\braket{jk} + \ket{j}\braket{ki} + \ket{k}\braket{ij} = 0 && \text{Schouten identity} \label{eq:schouten} \\
        \bra{i}\gamma^\mu \ketsq{i} = 2p_i^\mu && \text{Gordon identity} \label{eq:gordon} \\
        \bra{i} \gamma^\mu \ketsq{j} = \brasq{j}\gamma^\mu \ket{i} && \\
        \bra{i}\gamma^\mu \ketsq{j}^{\ast} = \bra{j}\gamma^\mu \ketsq{i} && \text{(for real momenta)} \\
        \bra{i}\gamma^\mu \ketsq{j} \bra{k}\gamma_\mu \ketsq{l} = -2\braket{ik}\braketsq{jl} && \text{Fierz identity} \label{eq:fierz} \,.
    \end{align}

\end{subequations}

In addition to massless fermions, we need to be able to write the polarisation vectors of massless spin\=/1 bosons in the spinor-helicity language. In analogy to Eq.~\ref{eq:outerproduct}, the Coulomb gauge identity $\varepsilon_{\pm} \cdot \varepsilon_{\pm} = 0$ \JK{Is this only true in Coulomb gauge?} allows us to decompose $\varepsilon^\mu$ into an outer product of two vectors. To this end, we introduce a reference vector $q^\mu$ and write \JK{double check the signs}:
\begin{align} \label{eq:pols}
    \varepsilon^\mu_{-}(p, q) = \frac{\bra{p}\gamma^\mu\ketsq{q}}{\sqrt{2}\braketsq{pq}} && \varepsilon^\mu_{+}(p, q) = \frac{\bra{q}\gamma^\mu\ketsq{p}}{\sqrt{2}\braket{qp}} \,.
\end{align}
The choice of the reference vector is arbitrary (apart from the condition $q^\mu \neq p^\mu$), which reflects gauge invariance. We can see this by noting that the Weyl spinors are two-component object and can be decomposed as $\ket{r} = \frac{\braket{rq}}{\braket{pq}}\ket{p} - \frac{\braket{rp}}{\braket{pq}}\ket{q}$. Therefore, any shift in $q$ must be of the form $q \rightarrow Aq + Bp$, where $A, B$ are constants. Then, from Eq.~\ref{eq:pols} (and using Eq.~\ref{eq:gordon}), it is easy to see that this shift will correspond to $\varepsilon^\mu \rightarrow \varepsilon^\mu + Cp^\mu$. Thus, the Ward identity $p_\mu \ampl{}{^\mu}$ is satisfied for any choice of the reference vector $q^\mu$. In practice, it is useful to choose it such that contracting $\varepsilon^\mu$ with external momenta leads to the formation of vanishing spinor brackets, thus greatly simplifying the algebra. Finally, the validity of Eq.~\ref{eq:pols} can be verified by observing that these expressions obey all identities we would expect from a polarisation vector \JK{I don't like this}:
\begin{subequations}
    \begin{align}
        p \cdot \varepsilon_\pm(p, q) &= 0 \\
        q \cdot \varepsilon_\pm(p, q) &= 0 \\
        \varepsilon_\pm (p, q) \cdot \varepsilon_\pm(p', q) &= 0 \\
        \varepsilon_\pm (p, q) \cdot \varepsilon_\mp(p', p) &= 0 \\
        \varepsilon_\pm^\ast (p, q) \cdot \varepsilon_\pm(p, q) &= -1
    \end{align}
\end{subequations}
At this point, we have all the tools we need to express any amplitude of massless fermions and spin\=/1 bosons through the angle and square brackets. Its usefulness, however, may not be immediately clear, especially given the notation which at first appears daunting. As a quick demonstration of the power of spinor-helicity formalism, let us consider the special case of 3-particle kinematics. For any three massless momenta satisfying $p_1^\mu + p_2^\mu + p_3^\mu = 0$, we have:
\begin{equation}
    \braket{12}\braketsq{21} = s_{12} = p_3^2 = 0\,.
\end{equation}
Thus, either $\braket{12} = 0$ or $\braketsq{12} = 0$. If we assume $\braket{12}$ is non-vanishing, then by momentum conservation and the massless Weyl equation:
\begin{equation}
    \braket{12}\braketsq{23} = \langle 1|\slashed{2}\ketsq{3} = -\langle 1|(\slashed{1}+\slashed{3})\ketsq{3} = 0\,.
\end{equation}
Thus, $\braketsq{23} = 0$ and in an analogous manner, we can show that $\braketsq{13} = 0$ as well. Had we assumed $\braketsq{12} \neq 0$, we would have found that all angle brackets vanish instead:
\begin{equation}
    \braketsq{12} = \braketsq{13} = \braketsq{23} = 0 \qquad \text{or} \qquad \braket{12} = \braket{13} = \braket{23} = 0 \,.
\end{equation}
Therefore, for 3-particle kinematics, the amplitude must depend on either square or angle brackets only. However, note that this result makes sense only if we work with complex momenta. Otherwise, through Eq.~\ref{eq:complexconjbracket}, the angle and square brackets are complex conjugates of each other and so both types must vanish simultaneously. Amplitudes constructed from complex momenta are of course not physical, nonetheless they provide a useful building block for higher-point amplitudes in recursive techniques \JK{reference to BCFW? Maybe I should have a mini-section on BCFW when talking about the tree amps for $\ppbbh$}.
\subsection{Little group scaling} \label{sec:littlegroup}
In the previous section, we saw that the freedom in choosing the reference vector $q^\mu$ reflects gauge invariance of the amplitude. Here we will see how another physical principle places strong constrains on the form of helicity amplitudes. We begin by observing that when trading the Weyl spinors for the bracket notation, there is some freedom in how exactly we write down Eq.~(\ref{eq:lambdatobraket}). That is, note that both $p_{a\dot{b}} = \ketsq{p}_a \bra{p}_{\dot{b}}$ and $p^{\dot{a}b} = \ket{p}^{\dot{a}} \brasq{p}^b$ are invariant under the transformation:
\begin{align} \label{eq:littlegroupscaling}
    \ket{i} \rightarrow z \ket{i} && \ketsq{i} \rightarrow z^{-1} \ketsq{i}, \qquad z \in \mathbb{C}  
\end{align}
This is known as \textbf{little group scaling}. Each external momentum has its own little-group transformation. This implies the following relations for spin-$1$ massless boson polarisations in Eq.~(\ref{eq:pols}):
\begin{align}
    \varepsilon^\mu_- (p,q) \rightarrow z^2 \varepsilon^\mu_- (p,q) &&  \varepsilon^\mu_+ (p,q) \rightarrow z^{-2} \varepsilon^\mu_+ (p,q) \,.
\end{align}
Note that the polarisation vectors are invariant under re-scalings of the reference momenta. Thus, for scattering of massless particles, the little-group scaling of the corresponding amplitude is determined by the helicities of the external particles. Specifically, if we re-scale the spinor brackets associated with the momentum $p_i$, the amplitude scales according to:
\begin{equation}
    A_n \left(\ldots, \{p_i, h_i\}, \ldots \right) \xrightarrow[\ketsq{i} \rightarrow z_i^{-1}\ketsq{i}]{\ket{i} \rightarrow z_i\ket{i}} z_i^{-2h_i}  A_n \left(\ldots, \{p_i, h_i\}, \ldots \right),
\end{equation}
where $h_i=\pm\frac{1}{2}$ for fermions and $h_i=\pm1$ for massless spin\=/1 bosons. It turns out that this property places a strong constraint on the spinor bracket expression of the amplitude. We will consider tree-level 3-gluon scattering as a basic example. We have already seen that for 3-particle kinematics, the amplitude must be written in terms of angle \textit{or} square brackets only, but we do not know the general form of the expression. Let us re-scale all three momenta with separate shifts $z_1, z_2, z_3$ in an MHV configuration. Then:
\begin{equation}
    A_3^{(0)} (1^-2^-3^+) \rightarrow z_1^2 z_2^2 z_3^{-2} A_3^{(0)}(1^-2^-3^+) \,.
\end{equation}
Assuming that this amplitude depends only on angle brackets:
\begin{equation} \label{eq:3gscaling}
    A_3^{(0)} (1^-2^-3^+) \propto \braket{12}^{x_{12}} \braket{13}^{x_{13}} \braket{23}^{x_{23}} \,,
\end{equation}
Using Eq.~\ref{eq:littlegroupscaling}, we solve for the exponents and get $\{x_{12} = 3, x_{13} = -1, x_{23} = -1\}$. An identical exercise can be performed (assuming square brackets this type) for the anti-MHV amplitude $A_3^{(0)} (1^+2^+3^-)$, leading to an analogous result. Therefore, the 3-point gluon amplitudes are fixed (up to an overall constant) by the special 3-point kinematics and little group scaling:
\begin{align} \label{eq:3gMHV}
    A_3^{(0)} (1^-2^-3^+) = \kappa_1 \frac{\braket{12}^3}{\braket{23}\braket{31}} && A_3^{(0)} (1^+2^+3^-) = \kappa_2 \frac{\braketsq{12}^3}{\braketsq{23}\braketsq{31}} \,.
\end{align}
We also note that flipping all helicities corresponds to exchanging $\braket{\phantom{p}} \leftrightarrow \braketsq{\phantom{p}}$. With a wrong choice of the bracket type in Eq.~\ref{eq:3gscaling}, one can show by considering the mass dimension of the amplitude that the couplings $\kappa_1$ and $\kappa_2$ would have to come from terms in the Lagrangian that are non-local\footnote{The mass dimension of $\ampl{n}{}$ in $D=4$ is $4-n$. From Eq.~\ref{eq:pslashed2}, we see that both $\braket{\phantom{i}}$ and $\braketsq$ must have mass dimension 1. Thus, the constants $\kappa_1$ and $\kappa_2$ in Eq.~\ref{eq:3gMHV} have mass dimension 0, which is consistent with the fact that they must have come from the 3-gluon interaction term in the Lagrangian (Eq.~\ref{eq:QCDLagrangian}), \textasciitilde$A^\mu A_\mu \partial^\nu A_\nu$. Had we assumed incorrect bracket types, both constants would need to have dimension 2. Thus, the corresponding term in the Lagrangian would be \textasciitilde$A^\mu A_\mu \frac{\partial^\nu}{\square} A_\nu$, which is non-local (it describes an interaction whose effects become more important with distance).}. We thus reject them as unphysical. Moreover, the same argument can be used to show that the $(---)$ and $(+++)$ configurations cannot have a non-vanishing amplitude:
\begin{align}
    A_3^{(0)} (1^-2^-3^-) = 0 && A_3^{(0)} (1^+2^+3^+) = 0\,.
\end{align}
In fact, the simplicity we have seen so far generalises to higher-point gluon amplitudes. With a smart choice of reference vectors, it can be shown that:
\begin{align}
    A_n^{(0)} (1^-2^- \ldots n^-) = 0 && A_n^{(0)} (1^+2^+ \ldots n^+) = 0\,,
\end{align}
as well as:
\begin{align}
    A_n^{(0)} (1^+2^- \ldots n^-) = 0 && A_n^{(0)} (1^-2^+ \ldots n^+) = 0\,.
\end{align}
The first non-vanishing amplitudes are the MHV/anti-MHV configurations:
\begin{align} \label{eq:ParkeTaylor}
    A_n^{(0)} (1^+2^+\ldots i^- \ldots j^- \ldots n^+) &= \frac{\braket{ij}^4}{\braket{12} \braket{23} \ldots \braket{n1}} \,, \\
    A_n^{(0)} (1^-2^-\ldots i^+ \ldots j^+ \ldots n^-) &= \frac{\braketsq{ij}^4}{\braketsq{12} \braketsq{23} \ldots \braketsq{n1}} \,.
\end{align}
This result is known as the Parke-Taylor formula \cite{Mangano:1990by}. It can be proved inductively using the BCFW recursion relations~\cite{Britto:2004ap, Britto:2005fq}, with the 3-point MHV amplitudes of Eq.~\ref{eq:3gMHV} serving as the starting point. Overall, it is now clear that the spinor-helicity formalism, together with little group scaling and locality of the Lagrangian, produce astonishingly compact results for amplitudes which are traditionally calculated as sums of hundreds or thousands of Feynman diagrams.
\section{Momentum twistors} \label{sec:MTs}
In the previous section, we have seen that the spinor-helicity formalism provides a convenient framework to describe helicity amplitudes. By using spinor brackets, which are intrinsically tied to helicity, we were able to exploit properties of the amplitude to arrive at remarkably neat expressions. Nonetheless, this formalism comes with certain drawbacks. Firstly, note that kinematic identities such as momentum conservation are not automatically satisfied by the spinor brackets. We can in fact use the properties listed in Eq.~\ref{eq:spinorsids} to arrive at a minimal set of these variables. In practice, however, this proves to be cumbersome, especially for high-multiplicity processes. Moreover, the appearance of square roots such as~\ref{eq:delta3} and \ref{eq:delta5} complicates our computational setup, which will be made clear in the next section. We would therefore like to have a parametrisation of external kinematics which solves both these problems simultaneously.

In recent years, many amplitude computations have exploited variables known as \textbf{momentum twistors} (MTs)~\cite{Hodges:2009hk, Badger:2013gxa, Badger:2016uuq}. As the first step, we define dual-space coordinates $x_i^\mu$ as:
\begin{equation} \label{eq:dualspacedef}
    p_i^\mu = x_i^\mu - x_{i+1}^\mu\,.
\end{equation}
Using the massless Weyl equation (Eq.~\ref{eq:weyleq}) and the slash notation in the sense of Eq.~\ref{eq:pslashed1}, it then follows that:
\begin{equation} \label{eq:incidencerel}
    \brasq{\mu_i} \equiv \bra{i}\slashed{x}_i = \bra{i}\slashed{x}_{i+1}\,,
\end{equation}
The new variables allow us to define the momentum twistors $Z_i^I$:
\begin{equation} \label{eq:momtwistor}
    Z_i^I = 
    \begin{pmatrix}
        \ket{i} \\
        \brasq{\mu_i} 
    \end{pmatrix}\,.
\end{equation}
where the index $I$ is understood as $I=\{\dot{a},a\}$. Since $\slashed{p} = \ket{i}\brasq{i}$, we can also express $\brasq{i}$ in terms of $Z_i^I$. To this end, the dual twistor is defined as:
\begin{equation} \label{eq:dualmomtwistor}
    W_i^I = 
    \begin{pmatrix}
        \ket{\mu_i} \\
        \brasq{i}
    \end{pmatrix} = 
    \frac{\varepsilon^{ABCD} Z_{(i-1)B} Z_{iC} Z_{(i+1)D}}{\braket{i-1, i} \braket{i, i+1}}\,,
\end{equation}
where $\varepsilon^{ABCD}$ is the 4-dimensional Levi\=/Civita symbol. We can then expand this equation and read off the last two components:
\begin{equation}
    \brasq{i} = \frac{\braket{i, i+1}\brasq{\mu_{i-1}} + \braket{i+1, i-1}\brasq{\mu_i} + \braket{i-1, i}\brasq{\mu_{i+1}} }{\braket{i-1, i}\braket{i, i+1}}\,.
\end{equation}
Each momentum twistor $Z_i^I$ has four components, thus the matrix of all twistors has $4n$ entries for $n$\=/particle scattering. However, not all of them are independent. Firstly, momentum twistors are invariant under the 10-dimensional Poincaré group. Additionally, they exhibit the $U(1)$ symmetry as well, for each particle separately. We can see this from Eq.~\ref{eq:incidencerel}, which implies that under the little group scaling of $\ket{i}\rightarrow t_i\ket{i}$, with $t_i \in \mathbb{C}$, the momentum twistors scale as: $Z_i \rightarrow t_i Z_i$. At the same time, this transformation does not affect the underlying momentum $p_i^\mu$, thus $Z_i$ are defined projectively. Therefore, the number of independent \textbf{momentum-twistor variables} needed to generate the $Z_i$ for $n$\=/particles is\footnote{In amplitude jargon, the term `momentum twistors' most often refers to these $3n-10$ independent variables, rather than the $Z_i$'s themselves. We will also adopt this terminology in subsequent sections.}: $4n-10-n\times1 = 3n-10$. \JK{Make sure to understand the $3n-10$ thing.} \JK{I forgot what it means to be defined projectively.}.

The momentum twistors $Z_i$, together with their dual equivalent $W_i$, serve as a useful way to generate numerical phase-space points according to the following recipe:
\begin{enumerate}
    \item Fill the twistor matrix $Z_i^I, i=1, \ldots, n$ with random integers.
    \item Compute the dual twistor matrix $W_i^I$.
    \item Read off spinors $\ket{i}$ and $\brasq{i}$.
    \item Calculate the momenta according to the Gordon identity, $p^\mu = \frac{1}{2}\brasq{i}\gamma^\mu |i\rangle$.
\end{enumerate}
Phase-space points generated in this manner are complex and rational. We can also populate the twistor matrix with rational functions instead. The corresponding phase-space parametrisation is guaranteed to automatically implement momentum conservation and the Schouten identity. It is also possible to make a specific choice which leads to $\tr_5$ being rational, which is a trick that will be useful in the next section\JK{Why do MTs rationalise $\tr_5$?}. It is not clear, however, how to choose these functions such that the corresponding parametrisation leads to the simplest possible amplitude expressions \JK{Mention how the MTs break symmetries of helicity amplitudes}. We will present two judicious \JK{Maybe `judicious' is too much?...} choices in Sections~\ref{sec:Hbb} and \ref{sec:Wyj}\JK{Why do we use different MT parametrisations in these papers?}.

A small drawback of using the momentum-twistor variables is that they lose the phase information carried by the spinor brackets $\ket{i}$ and $\brasq{i}$. This is because in reducing the number of independent variables from $4n$ to $3n-10$, imposing the symmetries essentially fixes the frame in which we evaluate the kinematics. Thus, strictly speaking, only phase-free expressions can be obtained in MT-variables. On the other hand, each helicity amplitude is a `phase-full' quantity (as opposed to the squared, spin-summed amplitude), therefore we need to restore this information at the end of our computation. This can be achieved by multiplying our MT-variable expression by any factor with the same phase content, normalised such that its magnitude is 1. In practice, we most often choose the spinor-bracket expression of the tree-level amplitude for the corresponding helicity, and divide it by its MT-variable expression.
\section{Finite fields} \label{sec:FF}
In the previous section, we have introduced a new, minimal set of independent variables that automatically implement constraints such as momentum conservation, as well as rationalise all square roots that appear in our kinematics. This is not just an elegant mathematical exercise. It turns out that momentum-twistor variables (henceforth referred to as just momentum twistors, MTs) provide us with a powerful computational framework that goes hand in hand with yet another tool we employ in amplitude computations.
\subsection{Rational numbers} \label{sec:ratnums}
The problem of enormous algebraic expressions plagues almost every calculation in QFT. At the same time, sweeping cancellations often occur, leading to much more compact answers. Indeed, we have already seen how at tree-level the MHV gluon amplitudes can be described by remarkably simple expressions, despite the fact that they come from hundreds, if not thousands, of Feynman diagrams. A key idea that has emerged over the past several years is to avoid this complexity at the intermediate stages of the computation by working with numerical expressions instead~\cite{Peraro:2016wsq, Peraro:2019svx, Klappert:2019emp, Klappert:2020aqs, Klappert:2020nbg, vonManteuffel:2014ixa, Abreu:2020xvt}. Crucially, the analytic dependence can still be recovered from the numerics at the very end. In this section, we introduce the concept of \textbf{finite fields} and show how it can be used to our advantage.

A finite field is a field with a finite number of elements. We are interested in finite fields of non-negative integers:
\begin{equation} \label{eq:ffdefinition}
    \mathbb{Z}_n = \{0, \ldots, n-1\}\,,    
\end{equation}
where $n$ is referred to as the size of the field. In particular, we will work with fields whose size is a large prime number $p$, as prime fields satisfy many properties which make the corresponding arithmetic especially simple. Basic operations, such as addition, subtraction and multiplication, are defined over $\mathbb{Z}_p$ through the standard modular arithmetic $\text{mod } p$. We can also define a multiplicative inverse $b\in \mathbb{Z}_p$ for all $a\neq0 \in \mathbb{Z}_p$:
\begin{equation}
    a^{-1} \equiv b \mod p \qquad \Longleftrightarrow \qquad ab = 1 \mod p\,.
\end{equation}
In fact, the existence of the inverse for all non-zero $a$ is guaranteed only for prime fields. We can see this by considering the following set:
\begin{equation}
    S = \{a, 2a, 3a, \ldots, (p-1)a\}\,.
\end{equation}
Now, note that for any two integers $x, x'$ such that: $x \neq x' \text{ mod } p$, we have:
\begin{equation}
    a(x-x') \neq 0 \mod p \qquad \qquad (a \neq 0) \,.
\end{equation}
This inequality, however, holds only because $\gcd(a, p) = 1$. It follows that the set $S \text{ mod } n$ contains all unique, non-zero elements of $\mathbb{Z}_p$, one of which must be 1. This proves the existence of the multiplicative inverse for all $a \neq 0$ (it can be calculated using the \textit{extended Euclidean algorithm}). Consequently, we can conclude that rational operations over $\mathbb{Z}_p$ are well-defined. Moreover, it allows us to define a map from rational numbers to the prime field, $\mathbb{Q} \rightarrow \mathbb{Z}_p\,$. For $q=\frac{x}{y} \in \mathbb{Q}\,$: 
\begin{equation}
    q \text{ mod } p = \left(x \times (y^{-1} \text{ mod } p \right) \text{ mod } p\,.
\end{equation}
This map is not invertible, since it maps infinitely many elements of $\mathbb{Q}$ onto the finite set $\mathbb{Z}_p$. Nonetheless, the rational numbers $q$ can be recovered from their image in $\mathbb{Z}_p$ with a very high probability using \textit{Wang's algorithm} \cite{10.1145/800206.806398, 10.1145/1089292.1089293}. This process is referred to as \textbf{rational reconstruction}. We remark that this algorithm is successful if  $|x|, |y| < \sqrt{p/2}\,$. Therefore, $p$ should be chosen sufficiently large so that it is possible to reconstruct all rational numbers appearing in the problem. However, this defeats the purpose of using finite fields in the first place, which was to keep the size of numbers below a certain bound imposed by modular arithmetic $\text{mod } p\,$. Moreover, from the practical point of view, we want to use the efficiency of machine-size integers, which means we are usually constrained to $p<2^{64}$. Fortunately, rational numbers exceeding such thresholds can be reconstructed without using prohibitively large prime fields. Recall the essence of the \textit{Chinese remainder theorem}: knowledge of the congruences of an integer $x$ modulo $\{n_1, n_2, \ldots, n_k\}$, where all the $n_i$ are pairwise co-prime, allows us to obtain the congruence of $x$ modulo $n_1n_2\ldots n_k$. The same idea holds even for our map $\mathbb{Q} \rightarrow \mathbb{Z}_p$. Thus, by calculating:
\begin{align}
    q = a_{p_1} &\mod p_1 \nonumber \\
    q = a_{p_2} &\mod p_2 \nonumber \\
    &\vdots \nonumber \\
    q = a_{p_k} &\mod p_k\,,
\end{align}
we can obtain:
\begin{equation}
    q = a_{p_1 p_2 \ldots p_k} \mod (p_1 p_2 \ldots p_k)\,.
\end{equation}
Hence, combining the images of $q$ over several prime fields $\mathbb{Z}_{p_i}$ allows us to use Wang's algorithm on $\mathbb{Z}_{p_1 p_2 \ldots p_k}$ and successfully reconstruct $q$ in $\mathbb{Q}$.
\subsection{Rational functions} \label{sec:ratfuncs}
So far, we have seen how we can exploit finite fields to keep the size of numerical expressions from growing throughout our computation\footnote{An alternative approach would be to use floating-point numbers instead of rational numbers, however this would quickly lead to issues with precision.}. It should not come as a surprise that this concept can be extended to allow for the reconstruction of not only rational numbers, but also rational functions in multiple variables. 

Let us consider the so-called \textbf{black box interpolation problem}. Suppose we have a set of $n$ variables $\mathbf{x}=\{x_1, x_2, \ldots, x_n\}$. These variables will serve as the arguments of a rational function $f(\mathbf{x})$. In general, the analytic form of $f$ is obtained by applying a series of rational operations on $\mathbf{x}$ . We do not know $f$ analytically at any of these steps, however we assume that we have a way of implementing them \textit{numerically} --- this is what we call the `black box'. Specifically, the numerical operations will be done over a prime field $\mathbb{Z}_p$. We start by evaluating the variables $\mathbf{x}$ at random numerical values in $\mathbb{Z}_p$. \JK{are they actually random? Idk how FF chooses the sample points.}We then apply the rational operations represented by $f$, all within the same prime field. After passing through this black box, the result is a number within that field, which we denote as $f(\mathbf{x}) \text{ mod } p$. Therefore, we have obtained one \textbf{sample point} of the analytic result corresponding to the initial values we chose for $\mathbf{x}$\JK{Maybe a bit pedantic: does `sample point' refer to the initial values of $\mathbf{x}$ or to the corresponding numerical evaluations of $f(\mathbf{x})$?}.

They key idea of finite field methods is that it is possible to reconstruct the full analytic dependence of $f(\mathbf{x})$, with coefficients of $x_i$ in $\mathbb{Q}$, by sampling it in this manner at multiple points. The first step of this procedure is in essence a linear fit problem \JK{Check if that's the correct term.}. Any multivariate rational function can be written as:
\begin{equation} \label{eq:ratfun}
     R(\mathbf{x}) = \frac{
     \sum_{\bm{\alpha}} a_{\bm{\alpha}} \mathbf{x}^{\bm{\alpha}}
     }{
     \sum_{\bm{\beta}} b_{\bm{\beta}} \mathbf{x}^{\bm{\beta}}
     }\,.
\end{equation}
Here, $a_{\bm{\alpha}}, b_{\bm{\beta}} \in \mathbb{Z}_p$ are coefficients of the multivariate monomials $\mathbf{x}^\alpha$:
\begin{equation}
    \mathbf{x}^\alpha = \prod_{i=1}^n x_i^{\alpha_i}
\end{equation}
and $\bm{\alpha}$ denotes a collective set of exponents $\bm{\alpha} = \{\alpha_1, \alpha_2, \ldots, \alpha_n\}$. It is also useful to define the \textit{total degree} of the monomial as the sum of all its exponents:
\begin{equation}
    \deg (\mathbf{x}^{\bm{\alpha}}) \equiv |\bm{\alpha}| = \sum_{i=1}^n \alpha_i\,.
\end{equation}
In the context of a rational function, the total degree $\degmax(f)$ is understood as the maximal total degree of any of its monomials.

With this representation of $f(\mathbf{x})$ in Eq.~\ref{eq:ratfun}, we can try to reconstruct its analytic dependence from the numerical samples over the prime field $\mathbb{Z}_p$. In a very naive approach, we would construct the most general ansatz covering all possible monomials up to degree $\degmax (f)$. We make this explicit by writing the ansatz as:
\begin{equation}
    R(\mathbf{x}) = \frac{
    \sum\limits_{\bm{\alpha}:\, |\bm{\alpha}| \le u} a_{\bm{\alpha}} \mathbf{x}^{\bm{\alpha}}
    }{
    \sum\limits_{\bm{\beta}:\, |\bm{\beta}| \le v} b_{\bm{\beta}} \mathbf{x}^{\bm{\beta}}
    }\,,
\end{equation}
where we have abbreviated the numerator/denominator degrees as $u=\degmax(\text{num}(f))$ and $v=\degmax(\text{den}(f))$. We can then formulate a system of linear equations in $a_{\bm{\alpha}}, b_{\bm{\beta}}$ by evaluating both the monomials $\mathbf{x}^{\bm{\alpha}}$ in the ansatz and the black box function $f(\mathbf{x})$ at a chosen value $\mathbf{x}_j$ in $\mathbb{Z}_p$:
\begin{align}
    \sum_{\bm{\alpha}} a_{\bm{\alpha}} \mathbf{x}_j^{\bm{\alpha}} - 
    f(\mathbf{x}_j) \sum_{\bm{\beta}} b_{\bm{\beta}} \mathbf{x}_j^{\bm{\beta}} = 0 
&&    
j \in \{1, \ldots, |R(\mathbf{x})|\} \,.
\end{align}
Finding the values of these coefficients requires solving the system using linear algebra methods. In order for the system to close \JK{Is that the right terminology?}, we need to perform such evaluations on as many sample points as the number of ansatz terms. This is far from optimal, however, since such a generic ansatz grows rapidly with both the degree as well as the number of variables. In fact, one can show that the number of terms present in $R(\mathbf{x})$ is \JK{I took this from SAGEX lectures, not sure if I should do a reference.}:
\begin{equation} \label{eq:naiveansatzlength}
    |R(\mathbf{x})| = 
    \begin{pmatrix}
        u + n \\
        n
    \end{pmatrix}
    +
    \begin{pmatrix}
        v + n \\
        n
    \end{pmatrix}\,.
\end{equation}
Since the time complexity of the corresponding Gaussian elimination is $\order{|R(\mathbf{x})|^3}$, this can prove prohibitively expensive. As an example, in practice we will be dealing with cases such as six-variable functions with $u=30, v=10$, which gives $|R(\mathbf{x})| \approx 2\times 10^6$. Row reducing such a system is simply not feasible \JK{Is this true for us or in general? Maybe on some supercomputer it would be possible. Idk what the corresponding time estimate is.}. Another complication arises due to the fact that in general, even though the black box operations are implemented numerically over finite fields, obtaining each evaluation of $f(\mathbf{x})$ in the field $\mathbb{Z}_p$ might still take a long time due to the number and complexity of these operations. We refer to this as the \textbf{evaluation time per point}.

Overall, it is clear that we need to avoid using such a naive ansatz to interpolate a rational function from its evaluation over finite fields. Besides, in most applications the polynomial degrees $u$ and $v$ are not known \textit{a priori}, so it is difficult to construct an ansatz in the first place. Fortunately, we can make use of more elaborate interpolation methods\footnote{For a detailed description of these methods and their implementation, see~\cite{Peraro:2016wsq}.}. For univariate polynomials, the strategy is based on Newton's polynomial representation~\cite{Abramowitz1965HandbookOM}. This method is particularly useful in cases where the total degree is not known, as it allows for the inclusion of higher-degree terms until their coefficients are found to be 0, at which point the iterative procedure terminates. For univariate rational functions, we distinguish between two further cases based on whether the degrees $u$ and $v$ are known or not. If they are known, it turns out that the naive ansatzing described above performs well enough, as for $n=1$ the ansatz length $|R(x_1)|$ in Eq.~\ref{eq:naiveansatzlength} is sufficiently small to allow for efficient row reduction of the system. Finally, if the degrees are not known, the reconstruction strategy is based on a rational generalisation of Newton's formula known as Thiele's interpolation formula~\cite{Abramowitz1965HandbookOM}. 

Multivariate reconstruction from finite fields can be achieved as well. For multivariate polynomials, it is sufficient to apply the univariate Newton's formula recursively. That is, a multivariate polynomial $P(\mathbf{x})$ is first treated as a univariate polynomial in $x_1$ with coefficients that are polynomials in $x_2, x_3, \ldots, x_n$. These coefficients then become the subject of $(n-1)$-variable reconstruction and so forth, up until $n=1$. Reconstructing multivariate rational functions is significantly more complicated. The strategy is also based on a recursive use of Newton's formula, but with some important modifications such as adding an auxiliary variable to $\mathbf{x}$. We refer the reader to Refs.~\cite{CUYT20111445, Peraro:2016wsq} for details.

Having completed the interpolation through one of the methods above, the only thing left to do is to recover the monomial coefficients in $\mathbb{Q}$ from their images $a_{\bm{\alpha}}, b_{\bm{\beta}} \in \mathbb{Z}_p$ using Wang's algorithm. As explained earlier, if one prime field $\mathbb{Z}_{p_1}$ is not enough, we can always perform the interpolation in another field $\mathbb{Z}_{p_2}$ and combine these results with the Chinese remainder theorem to obtain the interpolation in $\mathbb{Z}_{p_1 p_2}$. In this way, a rational function with arbitrarily large coefficients can be recovered. The reconstruction time can be estimated according to:
\begin{equation} \label{eq:rectimeschematic}
    \text{Reconstruction time} \approx (\text{number of sample points}) \times (\text{evaluation time per point})\,.
\end{equation}
It is of great practical importance to reduce both these factors as much as possible, which renders the reconstruction of increasingly complicated rational functions possible. We will elaborate on this topic in Sections~\ref{sec:Hbb} and \ref{sec:Wyj}.

Let us make three final remarks. Firstly, we emphasise that the reconstructed function is minimal in terms of the numerator and denominator degrees, that is $\gcd \left(\text{num}(f), \text{den}(f) \right) = 1$. Note that this is also needed for the reconstruction ansatz to be unique. Secondly, for functions which are homogeneous, in the sense that they satisfy:
\begin{align}
    f(\lambda \mathbf{x}) = \lambda^u f(\mathbf{x}) && \lambda \in \mathbb{C} \,,
\end{align}
where $u=\deg (f)$, it is possible to reduce the number of variables in the problem by one. This is easy to see if we define an auxiliary function:
\begin{equation}
    \tilde{f}(x_2, \ldots, x_n) \equiv f(x_1=1, x_2, \ldots, x_n)\,.
\end{equation}
Then, requiring the correct scaling gives:
\begin{equation}
    f(x_1, \ldots, x_n) = x_1^u \, \tilde{f}\left(\frac{x_2}{x_1}, \ldots, \frac{x_n}{x_1}\right) \,.
\end{equation}
Thus, we can reconstruct $\tilde{f}$ and restore the homogeneity of $f$ a posteriori. In our applications, even though the functions we will be dealing with are in general not homogeneous, it turns out we can still discard one variable. We will usually set $s_{12} = 1$ and recover its analytic dependence a posteriori through dimensional analysis \JK{I don't think I understand this.} \JK{Are these two methods of discarding a variable the same?}. Finally, recall from Sec.~\ref{sec:kinematics} the presence of square roots in the kinematics associated with the amplitude. This is a problem because it is not always possible to take a square root of a field element $a \in \mathbb{Z_p}$. Specifically, for a field of size $p>2$, there are only $(p+1)/2$ so-called quadratic residues, i.e. solutions to this equation $x^2-a=0$ in $\mathbb{Z}_p$ \cite{hardy2008introduction}. We can understand this by considering the following set of candidates residues:
\begin{equation}
    \left\{0^2, 1^2, \ldots, \left(\frac{p-1}{2}\right)^2  \right\}\,.
\end{equation}
Clearly, all the elements have a solution to the above equation in $\mathbb{Z}_p$, which is just $\left\{0, 1, \ldots, (p-1)/2 \right\}$. Therefore, they are valid residues. Moreover, note that we cannot add any more candidates to this set, because 
%The advantage of turning an analytic calculation into a black-box interpolation is that it reduces the problem of computing a function f into the one of providing a fast numerical evaluation for it. Since the reconstruction is independent of the algorithm used for the evaluation of f , it has a very broad spectrum of applications. Numerical calculations can in turn avoid issues such as large intermediate expressions, which affect many computations in high-energy physics. With this approach, the number of evaluations needed for the reconstruction of a function scales linearly with the number of terms of the result itself and is independent of the complexity of intermediate expressions which may appear using fully analytic techniques.

Overall, we have seen that any algorithm which can be expressed as a chain of rational operations can be implemented over finite fields. This applies to both pure rational numbers, as well as analytic expressions in the form of rational functions. This turns out to be tremendously useful, since many of the steps required in amplitude computations are precisely such rational transformations. Armed with this knowledge, we can move on to the next steps in our procedure.

\section{Reduction techniques} \label{sec:reduction}
Before we begin, let us briefly summarise what we have learnt so far about the workflow in Fig.~\ref{fig:outline}. First of all, 

%\section{Integration-by-parts relations} \label{sec:IBP}
%\subsection{Uniform transcendentality} \label{sec:UT}
%\subsection{Differential equations} \label{sec:DEs}
%\subsection{Symbols} \label{sec:symbols}
%\subsection{Syzygy relations} \label{sec:syzygies}
%
%\section{Special functions} \label{sec:specialfunctions}
%\subsection{Pentagon functions} \label{sec:Pentagon functions}
%\subsection{Generalised series expansion} \label{sec:DiffExp}
%\subsection{Auxiliary mass flow} \label{sec:AMFlow}
\end{document}